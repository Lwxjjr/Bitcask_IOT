package core

import (
	"fmt"
	"io"
	"os"
	"path/filepath"
	"sort"
	"sync"
	"time"
)

// DB æ˜¯æ•°æ®åº“çš„å¯¹å¤–é—¨é¢
// å®ƒè´Ÿè´£åè°ƒï¼šIndex (å†…å­˜å¤§è„‘) <-> Series (æ•°æ®ç¼“å†²) <-> Storage (ç£ç›˜è‚Œè‚‰)
type DB struct {
	manager *Manager // ç£ç›˜ç®¡ç†å™¨
	idx     *Index   // å†…å­˜ç´¢å¼•

	stopCh chan struct{}  // å…³é—­ä¿¡å·
	wg     sync.WaitGroup // ç­‰å¾…ç»„ (ç¡®ä¿åå°ä»»åŠ¡å®‰å…¨é€€å‡º)
}

// NewDB ğŸŸ¢ 1. å¯åŠ¨æ•°æ®åº“
// dirPath: æ•°æ®å­˜å‚¨ç›®å½• (ä¼šè‡ªåŠ¨åˆ›å»º/åŠ è½½ .vlog æ–‡ä»¶)
func NewDB(dirPath string) (*DB, error) {
	mgr, _ := newManager(dirPath, 0)
	idx := NewIndex()

	// ğŸŒŸ 1. æ‰“å¼€å­—å…¸æ–‡ä»¶ï¼Œå¹¶æŒ‚è½½åˆ° Index ä¸Šï¼Œå‡†å¤‡æ¥æ”¶æœªæ¥çš„æ–°è®¾å¤‡æ³¨å†Œ
	catalogPath := filepath.Join(dirPath, "catalog.idx")
	catalogFd, _ := os.OpenFile(catalogPath, os.O_CREATE|os.O_RDWR|os.O_APPEND, 0644)
	idx.catalogFd = catalogFd

	// ğŸŒŸ 2. ã€å¼€æœºç¬¬ä¸€æ­¥ã€‘ï¼šæ‰«æ catalog.idxï¼Œæ¢å¤å†…å­˜å­—å…¸å’Œ nextID æœ€å¤§å€¼ï¼
	loadCatalog(catalogFd, idx)

	// ğŸŒŸ 3. ã€å¼€æœºç¬¬äºŒæ­¥ã€‘ï¼šæ‰«ææ‰€æœ‰ .hint æ–‡ä»¶ã€‚
	// æ­¤æ—¶è¯»å‡ºæ¥çš„ Hint åªæœ‰ uint32ï¼Œä½†ä½ çš„å¤§è„‘å·²ç»å¯ä»¥é€šè¿‡ idx.idToName è®¤è¯†å®ƒä»¬äº†ï¼
	loadHintsFromDir(dirPath, idx)

	db := &DB{
		manager: mgr,
		idx:     idx,
		stopCh:  make(chan struct{}),
	}

	// è´Ÿè´£å®šæœŸæŠŠé•¿æ—¶é—´æœªå†™å…¥çš„æ•°æ®å¼ºåˆ¶åˆ·ç›˜
	db.startWorker()

	return db, nil
}

// â• è¡¥å…¨æå…¶ç®€å•çš„åŠ è½½å­—å…¸é€»è¾‘
func loadCatalog(file *os.File, idx *Index) {
	file.Seek(0, io.SeekStart) // ç¡®ä¿ä»å¤´å¼€å§‹è¯»
	maxID := uint32(0)

	for {
		id, name, err := DecodeCatalog(file)
		if err != nil {
			break // è¯»åˆ° EOF è·³å‡º
		}

		// æ¢å¤æ­£å‘å’Œåå‘æ˜ å°„
		idx.seriesMap[name] = newSeries(id)
		idx.idToName[id] = name
		if id > maxID {
			maxID = id
		}
	}

	// æ¢å¤è‡ªå¢ ID çš„èµ·ç‚¹ï¼Œé˜²æ­¢é‡å¯å ID é‡å¤è¦†ç›–æ—§æ•°æ®ï¼
	if maxID > 0 {
		idx.nextID = maxID + 1
	}
}

// loadHintsFromDir æ‰«ææ•°æ®ç›®å½•ï¼ŒæŒ‰å­—å…¸åºåŠ è½½æ‰€æœ‰ä¼´ç”Ÿç´¢å¼•æ–‡ä»¶
func loadHintsFromDir(dirPath string, idx *Index) error {
	pattern := filepath.Join(dirPath, "*.hint")
	files, err := filepath.Glob(pattern)
	if err != nil {
		return err
	}

	if len(files) == 0 {
		return nil // æ²¡æœ‰ Hint æ–‡ä»¶ï¼Œç›´æ¥æ”¾è¡Œ
	}

	// å¿…é¡»æŒ‰æ—¶é—´å­—å…¸åºæ’åˆ—ï¼ä¿è¯å†…å­˜é‡Œçš„ Meta å—æ˜¯å•è°ƒé€’å¢çš„
	sort.Strings(files)

	for _, file := range files {
		if err := processSingleHintFile(file, idx); err != nil {
			return err
		}
	}
	return nil
}

// processSingleHintFile é€‚é…äº†å…¨æ–°çš„ uint32 å®šé•¿è§£æï¼
func processSingleHintFile(filePath string, idx *Index) error {
	f, err := os.Open(filePath)
	if err != nil {
		return err
	}
	defer f.Close()

	for {
		// ğŸŒŸ 1. æé€Ÿè§£æï¼šç¬é—´åˆ‡ä¸‹ 38 å­—èŠ‚ï¼Œæ‹¿åˆ°çš„æ˜¯ uint32 ç±»å‹çš„ sensorIDï¼
		sensorID, meta, err := DecodeHint(f)
		if err != nil {
			if err == io.EOF {
				break // å®Œç¾è¯»å®Œ
			}
			return fmt.Errorf("Hintæ–‡ä»¶ %s æŸå: %v", filePath, err)
		}

		// ğŸŒŸ 2. æ ¸å¿ƒè”åŠ¨ï¼šé ç¬¬ä¸€æ­¥è¯»å‡ºæ¥çš„ Catalog å­—å…¸ï¼ŒæŠŠ uint32 ç¿»è¯‘å›åå­—ï¼
		idx.mu.RLock()
		name, ok := idx.idToName[sensorID]
		idx.mu.RUnlock()

		if !ok {
			// æç«¯å®¹é”™é˜²çº¿ï¼šå¦‚æœ Hint é‡Œæœ‰æ•°æ®ï¼Œä½†å­—å…¸é‡Œæ‰¾ä¸åˆ°å¯¹åº”çš„åå­—
			// è¯´æ˜è¿™æ‰¹æ•°æ®æˆäº†â€œå­¤å„¿â€ï¼Œç›´æ¥è·³è¿‡ï¼Œé˜²æ­¢å¼•å‘ææ…Œ (Panic)
			// fmt.Printf("âš ï¸ è­¦å‘Šï¼šå‘ç°å­¤å„¿åŒºå—ï¼ŒæœªçŸ¥ SensorID: %d\n", sensorID)
			continue
		}

		// ğŸŒŸ 3. è·å–å¯¹åº”çš„è®¾å¤‡ (å› ä¸ºå‰é¢ loadCatalog å·²ç»æŠŠå®ƒæ”¾è¿›å†…å­˜äº†ï¼Œè¿™é‡Œç»å¯¹èƒ½æ‹¿åˆ°)
		s := idx.getOrCreateSeries(name)

		// ğŸŒŸ 4. æŠŠè—å®å›¾æŒ‚è½½åˆ°è®¾å¤‡çš„è‚šå­é‡Œ
		s.mu.Lock()
		s.blocks = append(s.blocks, meta)
		s.mu.Unlock()
	}

	return nil
}

// ==========================================
// ğŸš€ å¯¹å¤– API (Public API)
// ==========================================

// Write âœï¸ 2. å†™å…¥æ•°æ®
// ä¹Ÿå°±æ˜¯ "å­˜"ï¼šå‘Šè¯‰æˆ‘æ˜¯è°ã€ä»€ä¹ˆæ—¶å€™ã€å¤šå°‘åº¦
func (db *DB) Write(sensorID string, timestamp int64, value float64) error {
	// 1. å°è£…æˆå†…éƒ¨ Point
	point := Point{
		Time:  timestamp,
		Value: value,
	}

	// 2. è·å–æˆ–åˆ›å»º Series (å†…å­˜ä¸­çš„ä¸“å±é€šé“)
	series := db.idx.getOrCreateSeries(sensorID)

	// 3. å°è¯•è¿½åŠ åˆ°å†…å­˜ Buffer
	// âš¡ï¸ æ ¸å¿ƒé»‘ç§‘æŠ€ï¼šå¦‚æœ Buffer æ»¡äº†ï¼ŒSeries ä¼š"çªƒå–"æ»¡çš„é‚£éƒ¨åˆ†æ•°æ®å¹¶è¿”å›ç»™æˆ‘ä»¬
	pointsToFlush := series.append(point)

	// 4. å¦‚æœå‘ç”Ÿäº†çªƒå–ï¼Œè¯´æ˜éœ€è¦è½ç›˜äº†
	if len(pointsToFlush) > 0 {
		return db.flushSeriesData(series, pointsToFlush)
	}

	return nil
}

// Query ğŸ” 3. æŸ¥è¯¢æ•°æ®
// ä¹Ÿå°±æ˜¯ "å–"ï¼šæŸ¥å‡ºä¸€æ®µæ—¶é—´å†…çš„æ‰€æœ‰ç‚¹
func (db *DB) Query(sensorID string, start, end int64) ([]Point, error) {
	// 1. æ‰¾è®¾å¤‡
	series := db.idx.getOrCreateSeries(sensorID)
	if series == nil {
		return nil, nil // æ²¡è¿™ä¸ªè®¾å¤‡ï¼Œç›´æ¥è¿”å›ç©º
	}

	var result []Point

	// 2. æŸ¥ç£ç›˜ (å†·æ•°æ® Cold Data)
	// ä» Series é‡Œæ‹¿å‡ºç¬¦åˆæ—¶é—´èŒƒå›´çš„"è—å®å›¾åæ ‡" (BlockMeta)
	blockMetas := series.findBlocks(start, end)

	for _, meta := range blockMetas {
		// æ‹¿ç€åæ ‡å»é—® Storage è¦ç‰©ç†æ•°æ®
		block, err := db.manager.readBlock(meta)
		if err != nil {
			return nil, fmt.Errorf("read block failed: %v", err)
		}

		// Block åªæ˜¯ç²—ç•¥çš„å—ï¼Œéœ€è¦è¿‡æ»¤å‡ºç²¾ç¡®ç¬¦åˆæ—¶é—´èŒƒå›´çš„ç‚¹
		for _, p := range block.Points {
			if p.Time >= start && p.Time <= end {
				result = append(result, p)
			}
		}
	}

	// 3. æŸ¥å†…å­˜ (çƒ­æ•°æ® Hot Data)
	// è·å–è¿˜æ²¡æ¥å¾—åŠè½ç›˜çš„æ•°æ®
	hotData := series.getHotData()
	for _, p := range hotData {
		if p.Time >= start && p.Time <= end {
			result = append(result, p)
		}
	}

	return result, nil
}

// Keys ğŸ”‘ 4. è·å–æ‰€æœ‰ SensorID
func (db *DB) Keys() []string {
	return db.idx.getAllKeys()
}

// Close ğŸ”´ 5. å…³é—­æ•°æ®åº“
// å®‰å…¨é€€å‡ºï¼Œé˜²æ­¢æ•°æ®ä¸¢å¤±
func (db *DB) Close() error {
	// 1. é€šçŸ¥åå°åç¨‹åœæ‰‹
	close(db.stopCh)
	db.wg.Wait()

	// 2. (å¯é€‰) è¿™é‡Œå¯ä»¥éå†æ‰€æœ‰ Series æ‰§è¡Œä¸€æ¬¡å¼ºåˆ¶ ForceFlushï¼Œç¡®ä¿å†…å­˜ä¸ä¸¢æ•°æ®

	// 3. å…³é—­åº•å±‚æ–‡ä»¶å¥æŸ„
	return db.manager.close()
}

// ==========================================
// ğŸ”’ å†…éƒ¨èƒ¶æ°´é€»è¾‘ (Internal Glue)
// ==========================================

// flushSeriesData æ˜¯è¿æ¥ å†…å­˜(Series) å’Œ ç£ç›˜(Storage) çš„æ¡¥æ¢
func (db *DB) flushSeriesData(series *Series, points []Point) error {
	// 1. ç»„è£… Block
	// DB çŸ¥é“ series.ID()ï¼Œä¹Ÿæ‹¿åˆ°äº† pointsï¼Œæ‰€ä»¥ç”±å®ƒæ¥æ‰“åŒ…
	block := NewBlock(series.ID, points)

	// 2. å†™ç£ç›˜
	// è¿™ä¸€æ­¥ä¼šå‘ç”Ÿï¼šåºåˆ—åŒ– -> å‹ç¼© -> å†™æ–‡ä»¶ -> å¯èƒ½è§¦å‘æ–‡ä»¶åˆ‡åˆ†(Rotate)
	meta, err := db.manager.writeBlock(block)
	if err != nil {
		return err
	}

	// 3. æ‹¿å›æ‰§
	// æŠŠå­˜å‚¨å±‚è¿”å›çš„ BlockMeta (æ–‡ä»¶åç§»é‡ç­‰) æŒ‚å› Series çš„ç´¢å¼•é“¾è¡¨ä¸Š
	series.addBlockMeta(meta)

	return nil
}

// ==========================================
// â° åå°ä»»åŠ¡ (Background Worker)
// ==========================================

func (db *DB) startWorker() {
	db.wg.Add(1)
	go func() {
		defer db.wg.Done()
		// æ¯ç§’å·¡é€»ä¸€æ¬¡
		ticker := time.NewTicker(1 * time.Second)
		defer ticker.Stop()

		for {
			select {
			case <-db.stopCh:
				return
			case <-ticker.C:
				db.checkForceFlush()
			}
		}
	}()
}

// checkForceFlush å·¡æ£€æ‰€æœ‰ Seriesï¼Œçœ‹è°çš„æ•°æ®å¤ªä¹…æ²¡åˆ·ç›˜
func (db *DB) checkForceFlush() {
	allSeries := db.idx.getAllSeries()
	for _, series := range allSeries {
		// Series å†…éƒ¨ä¼šåˆ¤æ–­ï¼šå¦‚æœæ•°æ®å­˜åœ¨ä¸”è¶…è¿‡ 60ç§’ æœªåˆ·ç›˜ï¼Œå°±è¿”å›æ•°æ®
		if points := series.checkForTicker(); len(points) > 0 {
			// å¤ç”¨æ ¸å¿ƒåˆ·ç›˜é€»è¾‘
			if err := db.flushSeriesData(series, points); err != nil {
				fmt.Printf("Error flushing series %d: %v\n", series.ID, err)
			}
		}
	}
}
